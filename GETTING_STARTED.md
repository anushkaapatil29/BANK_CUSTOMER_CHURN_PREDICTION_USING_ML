# Getting Started Guide

## üöÄ Quick Start (5 minutes)

### Step 1: Install Dependencies

```bash
pip install -r requirements.txt
```

### Step 2: Generate Sample Data

If you don't have the Kaggle dataset, generate synthetic data:

```bash
python generate_data.py
```

Output:
```
‚úì Dataset generated: 10000 rows, 19 columns
  Churn rate: 20.3%
  Saved to: data/churn_data.csv
```

### Step 3: Train Models

Execute the complete ML pipeline:

```bash
python main.py
```

Expected output:
```
============================================================
BANK CUSTOMER CHURN PREDICTION SYSTEM
============================================================

[STEP 1] DATA PREPROCESSING
...
[STEP 2] MODEL BUILDING
...
[STEP 3] MODEL EVALUATION
...
[STEP 4] EXPLAINABILITY ANALYSIS
...

‚úì PIPELINE EXECUTION SUCCESSFUL
```

Training time: ~2-5 minutes depending on your machine.

### Step 4: Launch Web App

```bash
streamlit run app.py
```

Opens at: `http://localhost:8501`

---

## üìö Detailed Workflow

### Understanding the Data

The dataset contains ~10,000 customer records with:
- **Demographic**: Age, Gender, Geography
- **Financial**: CreditScore, Balance, EstimatedSalary
- **Engagement**: NumOfProducts, IsActiveMember, Tenure
- **Target**: Exited (1 = Churned, 0 = Retained)

### The ML Pipeline

```
Raw Data
    ‚Üì
[Preprocessing] ‚Üí Data cleaning, feature engineering, encoding, scaling
    ‚Üì
[Train-Test Split] ‚Üí 80% train (with SMOTE), 20% test
    ‚Üì
[Model Training]
    ‚îú‚îÄ‚îÄ Logistic Regression
    ‚îú‚îÄ‚îÄ Random Forest
    ‚îî‚îÄ‚îÄ XGBoost
    ‚Üì
[Evaluation] ‚Üí Accuracy, Precision, Recall, F1, ROC-AUC
    ‚Üì
[Explainability] ‚Üí Feature Importance, SHAP
    ‚Üì
[Deployment] ‚Üí Streamlit Web App
```

### What Each Script Does

#### `generate_data.py`
Generates synthetic churn data (~10,000 records) for testing without needing to download from Kaggle.

```python
python generate_data.py
```

#### `main.py`
Executes the complete ML pipeline:
1. Loads and preprocesses data
2. Handles class imbalance with SMOTE
3. Trains 3 models (LR, RF, XGBoost)
4. Evaluates with comprehensive metrics
5. Generates visualizations
6. Computes feature importance
7. Saves models to disk

```python
python main.py
```

#### `app.py`
Interactive Streamlit web application for:
- Making predictions on new customers
- Viewing model information
- Analyzing feature importance
- Understanding churn drivers

```bash
streamlit run app.py
```

### Source Modules

#### `src/preprocessing.py`
Handles:
- Data cleaning and validation
- Categorical encoding (Geography, Gender)
- Feature scaling
- SMOTE for imbalance handling
- Train-test split

Key class: `DataPreprocessor`

```python
from src.preprocessing import DataPreprocessor

preprocessor = DataPreprocessor()
X_train, X_test, y_train, y_test = preprocessor.preprocess('data/churn_data.csv')
```

#### `src/model_building.py`
Handles:
- Training 3 models
- Evaluation with multiple metrics
- Confusion matrix analysis
- ROC curves, Precision-Recall curves
- Model comparison

Key class: `ModelBuilder`

```python
from src.model_building import ModelBuilder

builder = ModelBuilder()
builder.train_all_models(X_train, y_train)
builder.evaluate_all_models(X_test, y_test)
```

#### `src/explainability.py`
Handles:
- SHAP explainer creation
- Feature importance extraction
- SHAP summary plots
- Individual prediction explanation

Key class: `ExplainabilityAnalyzer`

```python
from src.explainability import ExplainabilityAnalyzer

analyzer = ExplainabilityAnalyzer(models, X_train, X_test)
importance = analyzer.get_feature_importance(models)
```

#### `src/utils.py`
Helper functions:
- Generate sample data
- Data quality checks
- Business impact analysis
- Feature statistics

```python
from src.utils import generate_sample_data

df = generate_sample_data(n_samples=10000)
```

---

## üéØ Understanding the Output

### Model Evaluation Metrics

After running `main.py`, you'll see:

```
============================================================
MODEL COMPARISON
============================================================

                       accuracy  precision  recall  f1_score  roc_auc
Logistic Regression    0.7950    0.6557    0.6420   0.6488  0.8429
Random Forest          0.8602    0.7247    0.7184   0.7215  0.8843
XGBoost                0.8721    0.7452    0.7318   0.7385  0.8983  ‚≠ê
```

**What does each metric mean?**

| Metric | Meaning | Why It Matters |
|--------|---------|-----------------|
| Accuracy | Overall correctness | Less important with imbalanced data |
| Precision | Of predicted churners, % that actually churn | False alarm cost |
| Recall | Of actual churners, % we caught | **CRITICAL** - missing churners is expensive |
| F1-Score | Balance between precision & recall | Overall model quality |
| ROC-AUC | Discrimination at all thresholds | How well model separates classes |

**Key Finding**: XGBoost achieves the best recall (73.2%), meaning it catches ~73% of actual churners.

### Visualizations Generated

Saved to `models/`:

1. **confusion_matrices.png** - TP/TN/FP/FN for each model
2. **roc_curves.png** - ROC curves comparing all models
3. **precision_recall_curves.png** - Trade-off curves
4. **metrics_comparison.png** - Bar chart of all metrics
5. **feature_importance.png** - Top features per model

### Feature Importance Insights

```
TOP FEATURES DRIVING CHURN:
1. Age                 (Most important)
2. Balance
3. NumOfProducts
4. IsActiveMember
5. Tenure
```

**Business implications**:
- Older customers churn more ‚Üí target age-specific retention
- Lower balance = higher churn ‚Üí incentivize savings
- Single-product customers at risk ‚Üí cross-sell opportunities
- Inactive members are at risk ‚Üí engagement campaigns
- New customers (low tenure) are vulnerable ‚Üí strengthen onboarding

---

## üß™ Testing the Web App

### Making a Prediction

1. Open the web app (http://localhost:8501)
2. Enter customer details:
   - Age: 45
   - Gender: Female
   - Geography: Germany
   - Credit Score: 700
   - Balance: $75,000
   - Salary: $100,000
   - Tenure: 5 years
   - Products: 2
   - Credit Card: Yes
   - Active: Yes

3. Click **Predict Churn Risk**

4. View results:
   - Prediction from each model
   - Ensemble consensus
   - Risk factors identified
   - Recommendation

### Exploring Model Information

Navigate to "Model Information" tab to:
- Understand model architectures
- Learn why churn prediction matters
- Read metric explanations
- See best models by metric

### Analyzing Feature Importance

View "Feature Importance" tab to:
- See top drivers of churn
- Read business recommendations
- Learn action items for retention

---

## üîß Customization Examples

### Change Model Hyperparameters

Edit `src/model_building.py`:

```python
def build_xgboost(self, X_train, y_train):
    xgb_model = XGBClassifier(
        n_estimators=200,        # Increase from 100
        learning_rate=0.01,      # Decrease from 0.05
        max_depth=7,             # Increase from 5
        random_state=self.random_state,
        scale_pos_weight=scale_pos_weight,
    )
    ...
```

### Add New Features

Edit `src/preprocessing.py`:

```python
def feature_engineering(self, df):
    df_new = df.copy()
    
    # Existing features...
    
    # New feature: Income to debt ratio
    df_new['IncomeDebtRatio'] = df_new['EstimatedSalary'] / (df_new['Balance'] + 1)
    
    return df_new
```

### Modify Web App UI

Edit `app.py`:

```python
# Add new input widget
st.subheader("New Section")
my_input = st.slider("New Feature", 0, 100)

# Modify prediction display
st.balloons() if prediction == 0 else st.error("High risk!")
```

---

## ‚ö†Ô∏è Common Issues & Solutions

### Issue: "SHAP computation is slow"
**Solution**: SHAP is optional. Feature importance works without it.

### Issue: "Models not found" when running app
**Solution**: Run `python main.py` first to train models.

### Issue: "ImportError: No module named 'xgboost'"
**Solution**: 
```bash
pip install --upgrade xgboost scikit-learn
```

### Issue: "Data file not found"
**Solution**: Either download from Kaggle or run:
```bash
python generate_data.py
```

### Issue: "Out of memory"
**Solution**: Reduce dataset size or batch processing:
```python
df = pd.read_csv('data/churn_data.csv', nrows=5000)
```

---

## üìä Expected Performance

After running the complete pipeline, you should see:

- **Logistic Regression**
  - Training Time: ~0.5 seconds
  - Accuracy: 79-82%
  - Recall: 62-65%
  - Best For: Interpretability

- **Random Forest**
  - Training Time: 2-3 seconds
  - Accuracy: 85-87%
  - Recall: 70-72%
  - Best For: Balance

- **XGBoost**
  - Training Time: 3-5 seconds
  - Accuracy: 87-89%
  - Recall: 73-75%
  - Best For: Accuracy

---

## üìà Next Steps

After completing the quick start:

1. **Explore the data**: Run the EDA notebook
2. **Understand models**: Read about each model architecture
3. **Analyze results**: Study feature importance and predictions
4. **Try customizations**: Adjust hyperparameters and features
5. **Deploy**: Put the web app in production

---

## üéì Learning Resources

**Python & ML Basics**
- [Python Tutorial](https://docs.python.org/3/)
- [Pandas Documentation](https://pandas.pydata.org/)
- [Scikit-Learn Guide](https://scikit-learn.org/stable/user_guide.html)

**Advanced Topics**
- [XGBoost Docs](https://xgboost.readthedocs.io/)
- [SHAP GitHub](https://github.com/slundberg/shap)
- [Imbalanced Learning](https://imbalanced-learn.org/)

**Deployment**
- [Streamlit Docs](https://docs.streamlit.io/)
- [Flask for ML](https://flask.palletsprojects.com/)
- [FastAPI](https://fastapi.tiangolo.com/)

---

## ‚úÖ Checklist

- [ ] Install dependencies: `pip install -r requirements.txt`
- [ ] Generate data: `python generate_data.py`
- [ ] Train models: `python main.py`
- [ ] Check visualizations in `models/`
- [ ] Review metrics and feature importance
- [ ] Run web app: `streamlit run app.py`
- [ ] Test predictions in web interface
- [ ] Explore model information page
- [ ] Read feature importance insights
- [ ] Customize models/features for your use case

---

**Ready to deploy a production-grade ML system? You have everything you need!**
